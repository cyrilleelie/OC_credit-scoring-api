{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c9fc6fe-f9f9-4633-aa01-51114c103ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HOME CREDIT DEFAULT RISK COMPETITION\n",
    "# Ce script est une solution pour la compétition Kaggle \"Home Credit Default Risk\".\n",
    "# La plupart des caractéristiques sont créées en appliquant des fonctions (min, max, mean, sum, var) \n",
    "# à des tables groupées. Peu de sélection de caractéristiques est effectuée, et le surapprentissage \n",
    "# (overfitting) peut être un problème car de nombreuses caractéristiques sont corrélées.\n",
    "# Idées clés utilisées :\n",
    "# - Diviser ou soustraire des caractéristiques importantes pour obtenir des taux (ex: annuité et revenu).\n",
    "# - Données Bureau : créer des caractéristiques spécifiques pour les crédits Actifs et Fermés.\n",
    "# - Demandes Précédentes : créer des caractéristiques spécifiques pour les demandes Approuvées et Refusées.\n",
    "# - Modularité : une fonction pour chaque table (sauf bureau_balance et application_test qui sont traitées avec leur table principale).\n",
    "# - Encodage One-Hot pour les caractéristiques catégorielles.\n",
    "# Toutes les tables sont jointes au DataFrame principal 'application' via la clé SK_ID_CURR (sauf bureau_balance).\n",
    "\n",
    "# Mise à jour du kernel original (16/06/2018) :\n",
    "# - Ajout de la caractéristique \"Payment Rate\".\n",
    "# - Suppression de l'index des caractéristiques.\n",
    "# - Utilisation de KFold standard (non stratifié) pour la validation croisée.\n",
    "\n",
    "# --- Importation des bibliothèques nécessaires ---\n",
    "import numpy as np  # Pour les opérations numériques (arrays, etc.)\n",
    "import pandas as pd  # Pour la manipulation des données (DataFrames)\n",
    "import gc  # Garbage collector, pour la gestion manuelle de la mémoire\n",
    "import time  # Pour mesurer le temps d'exécution\n",
    "import re  # Expressions régulières, utilisées pour nettoyer les noms de colonnes\n",
    "import lightgbm as lgb  # Bibliothèque pour le modèle LightGBM\n",
    "from contextlib import contextmanager  # Utilitaires pour les gestionnaires de contexte (ex: timer)\n",
    "from sklearn.metrics import roc_auc_score, roc_curve  # Métriques d'évaluation\n",
    "from sklearn.model_selection import KFold, StratifiedKFold  # Outils pour la validation croisée\n",
    "import matplotlib.pyplot as plt  # Pour la création de graphiques\n",
    "import seaborn as sns  # Pour des graphiques statistiques améliorés\n",
    "import warnings  # Pour gérer les avertissements Python\n",
    "\n",
    "# Ignore les avertissements de type FutureWarning pour un affichage plus propre de la sortie\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d7c8e78f-9bdd-41c0-ba84-e89ae0fa455a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Fonctions Utilitaires ---\n",
    "\n",
    "@contextmanager\n",
    "def timer(title):\n",
    "    \"\"\"\n",
    "    Gestionnaire de contexte pour chronométrer l'exécution d'un bloc de code.\n",
    "\n",
    "    Args:\n",
    "        title (str): Titre à afficher avec le temps d'exécution.\n",
    "    \"\"\"\n",
    "    t0 = time.time()  # Temps de début\n",
    "    yield  # Exécute le bloc de code à l'intérieur du 'with'\n",
    "    # Affiche le titre et le temps écoulé en secondes\n",
    "    print(\"{} - done in {:.0f}s\".format(title, time.time() - t0))\n",
    "\n",
    "def sanitize_lgbm_col_name(col_name):\n",
    "    \"\"\"\n",
    "    Nettoie un nom de colonne pour le rendre compatible avec LightGBM,\n",
    "    en remplaçant les caractères non alphanumériques (sauf '_') par '_'.\n",
    "\n",
    "    Args:\n",
    "        col_name (str): Nom de la colonne à nettoyer.\n",
    "\n",
    "    Returns:\n",
    "        str: Nom de colonne nettoyé.\n",
    "    \"\"\"\n",
    "    return re.sub(r'[^A-Za-z0-9_]+', '_', str(col_name))\n",
    "\n",
    "def one_hot_encoder(df, nan_as_category=True):\n",
    "    \"\"\"\n",
    "    Encode les colonnes catégorielles d'un DataFrame en utilisant One-Hot Encoding.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame à encoder.\n",
    "        nan_as_category (bool, optional): Si True, traite les NaN comme une catégorie distincte. \n",
    "                                          Par défaut à True.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame avec les colonnes catégorielles encodées.\n",
    "        list: Liste des noms des nouvelles colonnes créées par l'encodage.\n",
    "    \"\"\"\n",
    "    original_columns = list(df.columns)  # Sauvegarde des noms de colonnes originaux\n",
    "    # Sélectionne les colonnes de type 'object' (généralement des chaînes de caractères)\n",
    "    categorical_columns = [col for col in df.columns if df[col].dtype == 'object']\n",
    "    # Applique pd.get_dummies pour le One-Hot Encoding\n",
    "    df = pd.get_dummies(df, columns=categorical_columns, dummy_na=nan_as_category)\n",
    "    # Identifie les nouvelles colonnes ajoutées\n",
    "    new_columns = [c for c in df.columns if c not in original_columns]\n",
    "    return df, new_columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fc6820dc-2732-418a-91b4-51be6518473c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Fonctions de Prétraitement par Fichier de Données ---\n",
    "\n",
    "def application_train_test(num_rows=None, nan_as_category=False):\n",
    "    \"\"\"\n",
    "    Prétraite les fichiers application_train.csv et application_test.csv.\n",
    "    Combine les deux, nettoie les données, encode les catégories et crée de nouvelles caractéristiques.\n",
    "\n",
    "    Args:\n",
    "        num_rows (int, optional): Nombre de lignes à charger pour chaque fichier (utile pour le débogage).\n",
    "                                  Par défaut à None (charge tout).\n",
    "        nan_as_category (bool, optional): Pour one_hot_encoder, indique si les NaN doivent être une catégorie.\n",
    "                                          Ici, il est False par défaut, contrairement à d'autres fonctions.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame combiné et prétraité.\n",
    "    \"\"\"\n",
    "    # Lecture des données d'entraînement et de test\n",
    "    df = pd.read_csv('./data/application_train.csv', nrows=num_rows)\n",
    "    test_df = pd.read_csv('./data/application_test.csv', nrows=num_rows)\n",
    "    print(\"Train samples: {}, test samples: {}\".format(len(df), len(test_df)))\n",
    "    \n",
    "    # Concaténation des dataframes train et test pour un traitement uniforme\n",
    "    df = pd.concat([df, test_df]).reset_index(drop=True) # drop=True évite d'ajouter l'ancien index comme colonne\n",
    "    \n",
    "    # Nettoyage de données spécifique\n",
    "    # Suppression des quelques applications avec CODE_GENDER 'XNA'\n",
    "    df = df[df['CODE_GENDER'] != 'XNA']\n",
    "    \n",
    "    # Encodage binaire pour les caractéristiques avec seulement deux catégories attendues\n",
    "    for bin_feature in ['CODE_GENDER', 'FLAG_OWN_CAR', 'FLAG_OWN_REALTY']:\n",
    "        df[bin_feature], uniques = pd.factorize(df[bin_feature]) # factorize assigne 0, 1, ... à chaque catégorie\n",
    "        \n",
    "    # Encodage One-Hot pour les autres caractéristiques catégorielles\n",
    "    df, cat_cols = one_hot_encoder(df, nan_as_category)\n",
    "    \n",
    "    # Traitement des valeurs NaN pour DAYS_EMPLOYED: 365243 (valeur sentinelle) est remplacée par NaN\n",
    "    df['DAYS_EMPLOYED'].replace(365243, np.nan, inplace=True)\n",
    "    \n",
    "    # Création de nouvelles caractéristiques (Feature Engineering) - souvent des ratios\n",
    "    df['DAYS_EMPLOYED_PERC'] = df['DAYS_EMPLOYED'] / df['DAYS_BIRTH']  # % de la vie passé à travailler\n",
    "    df['INCOME_CREDIT_PERC'] = df['AMT_INCOME_TOTAL'] / df['AMT_CREDIT'] # Ratio revenu / montant du crédit\n",
    "    df['INCOME_PER_PERSON'] = df['AMT_INCOME_TOTAL'] / df['CNT_FAM_MEMBERS'] # Revenu par personne dans la famille\n",
    "    df['ANNUITY_INCOME_PERC'] = df['AMT_ANNUITY'] / df['AMT_INCOME_TOTAL'] # Ratio annuité / revenu\n",
    "    df['PAYMENT_RATE'] = df['AMT_ANNUITY'] / df['AMT_CREDIT'] # Taux de paiement (annuité / crédit)\n",
    "    \n",
    "    del test_df  # Libération de la mémoire\n",
    "    gc.collect() # Appel explicite du garbage collector\n",
    "    return df\n",
    "\n",
    "def bureau_and_balance(num_rows=None, nan_as_category=True):\n",
    "    \"\"\"\n",
    "    Prétraite bureau.csv et bureau_balance.csv.\n",
    "    Effectue des agrégations sur bureau_balance, les joint à bureau,\n",
    "    puis agrège le résultat par SK_ID_CURR.\n",
    "\n",
    "    Args:\n",
    "        num_rows (int, optional): Nombre de lignes à charger.\n",
    "        nan_as_category (bool, optional): Pour one_hot_encoder.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame agrégé contenant des caractéristiques issues de bureau et bureau_balance.\n",
    "    \"\"\"\n",
    "    bureau = pd.read_csv('./data/bureau.csv', nrows=num_rows)\n",
    "    bb = pd.read_csv('./data/bureau_balance.csv', nrows=num_rows)\n",
    "    \n",
    "    # Encodage One-Hot pour les deux dataframes\n",
    "    bb, bb_cat = one_hot_encoder(bb, nan_as_category)\n",
    "    bureau, bureau_cat = one_hot_encoder(bureau, nan_as_category)\n",
    "    \n",
    "    # Agrégations sur bureau_balance (bb)\n",
    "    bb_aggregations = {'MONTHS_BALANCE': ['min', 'max', 'size']} # Statistiques de base pour MONTHS_BALANCE\n",
    "    for col in bb_cat:  # Pour les colonnes one-hot encodées de bb, calculer la moyenne\n",
    "        bb_aggregations[col] = ['mean']\n",
    "    bb_agg = bb.groupby('SK_ID_BUREAU').agg(bb_aggregations) # Grouper par SK_ID_BUREAU\n",
    "    # Renommer les colonnes agrégées pour éviter les MultiIndex et clarifier l'origine\n",
    "    bb_agg.columns = pd.Index([e[0] + \"_\" + e[1].upper() for e in bb_agg.columns.tolist()])\n",
    "    \n",
    "    # Joindre les agrégats de bb à bureau\n",
    "    bureau = bureau.join(bb_agg, how='left', on='SK_ID_BUREAU')\n",
    "    bureau.drop(['SK_ID_BUREAU'], axis=1, inplace=True) # SK_ID_BUREAU n'est plus nécessaire après la jointure\n",
    "    del bb, bb_agg # Libération de mémoire\n",
    "    gc.collect()\n",
    "    \n",
    "    # Agrégations sur bureau (maintenant enrichi avec les infos de bb)\n",
    "    # Définition des agrégations numériques\n",
    "    num_aggregations = {\n",
    "        'DAYS_CREDIT': ['min', 'max', 'mean', 'var'],\n",
    "        'DAYS_CREDIT_ENDDATE': ['min', 'max', 'mean'],\n",
    "        'DAYS_CREDIT_UPDATE': ['mean'],\n",
    "        'CREDIT_DAY_OVERDUE': ['max', 'mean'],\n",
    "        'AMT_CREDIT_MAX_OVERDUE': ['mean'],\n",
    "        'AMT_CREDIT_SUM': ['max', 'mean', 'sum'],\n",
    "        'AMT_CREDIT_SUM_DEBT': ['max', 'mean', 'sum'],\n",
    "        'AMT_CREDIT_SUM_OVERDUE': ['mean'],\n",
    "        'AMT_CREDIT_SUM_LIMIT': ['mean', 'sum'],\n",
    "        'AMT_ANNUITY': ['max', 'mean'],\n",
    "        'CNT_CREDIT_PROLONG': ['sum'],\n",
    "        'MONTHS_BALANCE_MIN': ['min'], # Vient de bb_agg joint\n",
    "        'MONTHS_BALANCE_MAX': ['max'],  # Vient de bb_agg joint\n",
    "        'MONTHS_BALANCE_SIZE': ['mean', 'sum'] # Vient de bb_agg joint\n",
    "    }\n",
    "    # Définition des agrégations catégorielles (moyenne des colonnes one-hot)\n",
    "    cat_aggregations = {}\n",
    "    for cat in bureau_cat: cat_aggregations[cat] = ['mean'] # Pour les OHE de bureau\n",
    "    for cat in bb_cat: cat_aggregations[cat + \"_MEAN\"] = ['mean'] # Pour les OHE de bureau_balance (déjà agrégées une fois)\n",
    "    \n",
    "    # Application des agrégations groupées par SK_ID_CURR\n",
    "    bureau_agg = bureau.groupby('SK_ID_CURR').agg({**num_aggregations, **cat_aggregations})\n",
    "    # Renommage des colonnes avec un préfixe 'BURO_'\n",
    "    bureau_agg.columns = pd.Index(['BURO_' + e[0] + \"_\" + e[1].upper() for e in bureau_agg.columns.tolist()])\n",
    "    \n",
    "    # Caractéristiques spécifiques pour les crédits 'Actifs'\n",
    "    # Sélectionne les crédits actifs (colonne 'CREDIT_ACTIVE_Active' créée par OHE)\n",
    "    active = bureau[bureau['CREDIT_ACTIVE_Active'] == 1] \n",
    "    active_agg = active.groupby('SK_ID_CURR').agg(num_aggregations) # Agrégations numériques uniquement\n",
    "    active_agg.columns = pd.Index(['ACTIVE_' + e[0] + \"_\" + e[1].upper() for e in active_agg.columns.tolist()])\n",
    "    bureau_agg = bureau_agg.join(active_agg, how='left', on='SK_ID_CURR') # Jointure à bureau_agg\n",
    "    del active, active_agg\n",
    "    gc.collect()\n",
    "    \n",
    "    # Caractéristiques spécifiques pour les crédits 'Fermés'\n",
    "    closed = bureau[bureau['CREDIT_ACTIVE_Closed'] == 1] # Sélectionne les crédits fermés\n",
    "    closed_agg = closed.groupby('SK_ID_CURR').agg(num_aggregations) # Agrégations numériques uniquement\n",
    "    closed_agg.columns = pd.Index(['CLOSED_' + e[0] + \"_\" + e[1].upper() for e in closed_agg.columns.tolist()])\n",
    "    bureau_agg = bureau_agg.join(closed_agg, how='left', on='SK_ID_CURR') # Jointure à bureau_agg\n",
    "    del closed, closed_agg, bureau\n",
    "    gc.collect()\n",
    "    \n",
    "    return bureau_agg\n",
    "\n",
    "def previous_applications(num_rows=None, nan_as_category=True):\n",
    "    \"\"\"\n",
    "    Prétraite previous_application.csv.\n",
    "    Effectue des agrégations par SK_ID_CURR, avec des caractéristiques spécifiques\n",
    "    pour les demandes approuvées et refusées.\n",
    "\n",
    "    Args:\n",
    "        num_rows (int, optional): Nombre de lignes à charger.\n",
    "        nan_as_category (bool, optional): Pour one_hot_encoder.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame agrégé.\n",
    "    \"\"\"\n",
    "    prev = pd.read_csv('./data/previous_application.csv', nrows=num_rows)\n",
    "    prev, cat_cols = one_hot_encoder(prev, nan_as_category=True)\n",
    "    \n",
    "    # Remplacement des valeurs sentinelles 365243 par NaN pour plusieurs colonnes de jours\n",
    "    prev['DAYS_FIRST_DRAWING'].replace(365243, np.nan, inplace=True)\n",
    "    prev['DAYS_FIRST_DUE'].replace(365243, np.nan, inplace=True)\n",
    "    prev['DAYS_LAST_DUE_1ST_VERSION'].replace(365243, np.nan, inplace=True)\n",
    "    prev['DAYS_LAST_DUE'].replace(365243, np.nan, inplace=True)\n",
    "    prev['DAYS_TERMINATION'].replace(365243, np.nan, inplace=True)\n",
    "    \n",
    "    # Nouvelle caractéristique : ratio montant demandé / montant de crédit accordé\n",
    "    prev['APP_CREDIT_PERC'] = prev['AMT_APPLICATION'] / prev['AMT_CREDIT']\n",
    "    \n",
    "    # Définition des agrégations numériques\n",
    "    num_aggregations = {\n",
    "        'AMT_ANNUITY': ['min', 'max', 'mean'],\n",
    "        'AMT_APPLICATION': ['min', 'max', 'mean'],\n",
    "        'AMT_CREDIT': ['min', 'max', 'mean'],\n",
    "        'APP_CREDIT_PERC': ['min', 'max', 'mean', 'var'],\n",
    "        'AMT_DOWN_PAYMENT': ['min', 'max', 'mean'],\n",
    "        'AMT_GOODS_PRICE': ['min', 'max', 'mean'],\n",
    "        'HOUR_APPR_PROCESS_START': ['min', 'max', 'mean'],\n",
    "        'RATE_DOWN_PAYMENT': ['min', 'max', 'mean'],\n",
    "        'DAYS_DECISION': ['min', 'max', 'mean'],\n",
    "        'CNT_PAYMENT': ['mean', 'sum'],\n",
    "    }\n",
    "    # Définition des agrégations catégorielles (moyenne des colonnes one-hot)\n",
    "    cat_aggregations = {}\n",
    "    for cat in cat_cols:\n",
    "        cat_aggregations[cat] = ['mean']\n",
    "    \n",
    "    # Agrégation principale par SK_ID_CURR\n",
    "    prev_agg = prev.groupby('SK_ID_CURR').agg({**num_aggregations, **cat_aggregations})\n",
    "    prev_agg.columns = pd.Index(['PREV_' + e[0] + \"_\" + e[1].upper() for e in prev_agg.columns.tolist()])\n",
    "    \n",
    "    # Caractéristiques spécifiques pour les demandes approuvées\n",
    "    # Sélectionne les demandes approuvées (colonne 'NAME_CONTRACT_STATUS_Approved' créée par OHE)\n",
    "    approved = prev[prev['NAME_CONTRACT_STATUS_Approved'] == 1]\n",
    "    approved_agg = approved.groupby('SK_ID_CURR').agg(num_aggregations) # Agrégations numériques\n",
    "    approved_agg.columns = pd.Index(['APPROVED_' + e[0] + \"_\" + e[1].upper() for e in approved_agg.columns.tolist()])\n",
    "    prev_agg = prev_agg.join(approved_agg, how='left', on='SK_ID_CURR') # Jointure\n",
    "    \n",
    "    # Caractéristiques spécifiques pour les demandes refusées\n",
    "    refused = prev[prev['NAME_CONTRACT_STATUS_Refused'] == 1] # Sélectionne les demandes refusées\n",
    "    refused_agg = refused.groupby('SK_ID_CURR').agg(num_aggregations) # Agrégations numériques\n",
    "    refused_agg.columns = pd.Index(['REFUSED_' + e[0] + \"_\" + e[1].upper() for e in refused_agg.columns.tolist()])\n",
    "    prev_agg = prev_agg.join(refused_agg, how='left', on='SK_ID_CURR') # Jointure\n",
    "    \n",
    "    del refused, refused_agg, approved, approved_agg, prev # Libération de mémoire\n",
    "    gc.collect()\n",
    "    return prev_agg\n",
    "\n",
    "def pos_cash(num_rows=None, nan_as_category=True):\n",
    "    \"\"\"\n",
    "    Prétraite POS_CASH_balance.csv.\n",
    "    Effectue des agrégations par SK_ID_CURR.\n",
    "\n",
    "    Args:\n",
    "        num_rows (int, optional): Nombre de lignes à charger.\n",
    "        nan_as_category (bool, optional): Pour one_hot_encoder.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame agrégé.\n",
    "    \"\"\"\n",
    "    pos = pd.read_csv('./data/POS_CASH_balance.csv', nrows=num_rows)\n",
    "    pos, cat_cols = one_hot_encoder(pos, nan_as_category=True)\n",
    "    \n",
    "    # Définition des agrégations\n",
    "    aggregations = {\n",
    "        'MONTHS_BALANCE': ['max', 'mean', 'size'], # Stats sur la balance mensuelle\n",
    "        'SK_DPD': ['max', 'mean'], # Stats sur les jours de retard de paiement (DPD)\n",
    "        'SK_DPD_DEF': ['max', 'mean'] # Stats sur les DPD avec tolérance\n",
    "    }\n",
    "    for cat in cat_cols: # Moyenne pour les colonnes one-hot encodées\n",
    "        aggregations[cat] = ['mean']\n",
    "    \n",
    "    pos_agg = pos.groupby('SK_ID_CURR').agg(aggregations) # Agrégation par SK_ID_CURR\n",
    "    pos_agg.columns = pd.Index(['POS_' + e[0] + \"_\" + e[1].upper() for e in pos_agg.columns.tolist()])\n",
    "    \n",
    "    # Compter le nombre total d'enregistrements POS CASH par client\n",
    "    pos_agg['POS_COUNT'] = pos.groupby('SK_ID_CURR').size()\n",
    "    \n",
    "    del pos # Libération de mémoire\n",
    "    gc.collect()\n",
    "    return pos_agg\n",
    "    \n",
    "def installments_payments(num_rows=None, nan_as_category=True):\n",
    "    \"\"\"\n",
    "    Prétraite installments_payments.csv.\n",
    "    Crée de nouvelles caractéristiques liées aux paiements et effectue des agrégations.\n",
    "\n",
    "    Args:\n",
    "        num_rows (int, optional): Nombre de lignes à charger.\n",
    "        nan_as_category (bool, optional): Pour one_hot_encoder.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame agrégé.\n",
    "    \"\"\"\n",
    "    ins = pd.read_csv('./data/installments_payments.csv', nrows=num_rows)\n",
    "    ins, cat_cols = one_hot_encoder(ins, nan_as_category=True)\n",
    "    \n",
    "    # Nouvelles caractéristiques\n",
    "    # Pourcentage payé par rapport à l'échéance\n",
    "    ins['PAYMENT_PERC'] = ins['AMT_PAYMENT'] / ins['AMT_INSTALMENT']\n",
    "    # Différence entre le montant dû et le montant payé\n",
    "    ins['PAYMENT_DIFF'] = ins['AMT_INSTALMENT'] - ins['AMT_PAYMENT']\n",
    "    # Jours de retard de paiement (DPD) et jours d'avance de paiement (DBD)\n",
    "    # S'assure que DPD et DBD sont >= 0\n",
    "    ins['DPD'] = ins['DAYS_ENTRY_PAYMENT'] - ins['DAYS_INSTALMENT']\n",
    "    ins['DBD'] = ins['DAYS_INSTALMENT'] - ins['DAYS_ENTRY_PAYMENT']\n",
    "    ins['DPD'] = ins['DPD'].apply(lambda x: x if x > 0 else 0)\n",
    "    ins['DBD'] = ins['DBD'].apply(lambda x: x if x > 0 else 0)\n",
    "    \n",
    "    # Définition des agrégations\n",
    "    aggregations = {\n",
    "        'NUM_INSTALMENT_VERSION': ['nunique'], # Nombre de versions d'échéancier uniques\n",
    "        'DPD': ['max', 'mean', 'sum'],\n",
    "        'DBD': ['max', 'mean', 'sum'],\n",
    "        'PAYMENT_PERC': ['max', 'mean', 'sum', 'var'],\n",
    "        'PAYMENT_DIFF': ['max', 'mean', 'sum', 'var'],\n",
    "        'AMT_INSTALMENT': ['max', 'mean', 'sum'],\n",
    "        'AMT_PAYMENT': ['min', 'max', 'mean', 'sum'],\n",
    "        'DAYS_ENTRY_PAYMENT': ['max', 'mean', 'sum'] # Jours auxquels les paiements ont été enregistrés\n",
    "    }\n",
    "    for cat in cat_cols: # Moyenne pour les colonnes one-hot\n",
    "        aggregations[cat] = ['mean']\n",
    "        \n",
    "    ins_agg = ins.groupby('SK_ID_CURR').agg(aggregations) # Agrégation par SK_ID_CURR\n",
    "    ins_agg.columns = pd.Index(['INSTAL_' + e[0] + \"_\" + e[1].upper() for e in ins_agg.columns.tolist()])\n",
    "    \n",
    "    # Compter le nombre total d'échéances par client\n",
    "    ins_agg['INSTAL_COUNT'] = ins.groupby('SK_ID_CURR').size()\n",
    "    \n",
    "    del ins # Libération de mémoire\n",
    "    gc.collect()\n",
    "    return ins_agg\n",
    "\n",
    "def credit_card_balance(num_rows=None, nan_as_category=True):\n",
    "    \"\"\"\n",
    "    Prétraite credit_card_balance.csv.\n",
    "    Effectue des agrégations larges sur les données de carte de crédit.\n",
    "\n",
    "    Args:\n",
    "        num_rows (int, optional): Nombre de lignes à charger.\n",
    "        nan_as_category (bool, optional): Pour one_hot_encoder.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame agrégé.\n",
    "    \"\"\"\n",
    "    cc = pd.read_csv('./data/credit_card_balance.csv', nrows=num_rows)\n",
    "    cc, cat_cols = one_hot_encoder(cc, nan_as_category=True)\n",
    "    \n",
    "    # Suppression de SK_ID_PREV car l'agrégation se fait par SK_ID_CURR\n",
    "    cc.drop(['SK_ID_PREV'], axis=1, inplace=True)\n",
    "    # Agrégation générale (min, max, mean, sum, var) sur toutes les colonnes restantes\n",
    "    cc_agg = cc.groupby('SK_ID_CURR').agg(['min', 'max', 'mean', 'sum', 'var'])\n",
    "    # Renommage des colonnes (aplatissement du MultiIndex)\n",
    "    cc_agg.columns = pd.Index(['CC_' + e[0] + \"_\" + e[1].upper() for e in cc_agg.columns.tolist()])\n",
    "    \n",
    "    # Compter le nombre de lignes de carte de crédit par client\n",
    "    cc_agg['CC_COUNT'] = cc.groupby('SK_ID_CURR').size()\n",
    "\n",
    "    # Boucle de conversion de type ajoutée pendant le débogage\n",
    "    # S'assure que les colonnes potentiellement 'object' après agrégation sont converties en numérique\n",
    "    for col_name in cc_agg.columns:\n",
    "        if cc_agg[col_name].dtype == 'object':\n",
    "            print(f\"Dans credit_card_balance, la colonne '{col_name}' est de type object. Tentative de conversion en numérique.\")\n",
    "            cc_agg[col_name] = pd.to_numeric(cc_agg[col_name], errors='coerce') # errors='coerce' met NaN si la conversion échoue\n",
    "            if cc_agg[col_name].isnull().all() and len(cc_agg[col_name]) > 0:\n",
    "                print(f\"Attention : La colonne '{col_name}' est maintenant entièrement NaN après la conversion.\")\n",
    "    \n",
    "    del cc # Libération de mémoire\n",
    "    gc.collect()\n",
    "    return cc_agg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ce889b46-4c5a-4bfa-a054-e78ea88d7b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Fonction de Modélisation ---\n",
    "\n",
    "def kfold_lightgbm(df, num_folds, stratified=False, debug=False):\n",
    "    \"\"\"\n",
    "    Entraîne un modèle LightGBM en utilisant la validation croisée K-Fold.\n",
    "    Génère des prédictions out-of-fold et des prédictions pour le jeu de test.\n",
    "    Calcule et affiche l'importance des caractéristiques.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame complet contenant les données d'entraînement et de test fusionnées et prétraitées.\n",
    "        num_folds (int): Nombre de plis pour la validation croisée.\n",
    "        stratified (bool, optional): Si True, utilise StratifiedKFold. Par défaut à False (utilise KFold).\n",
    "        debug (bool, optional): Si True, des étapes de débogage peuvent être activées (non utilisé dans cette version pour le comportement du modèle).\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame contenant l'importance des caractéristiques.\n",
    "    \"\"\"\n",
    "    # Séparation des données d'entraînement et de test en fonction de la présence de la colonne 'TARGET'\n",
    "    train_df = df[df['TARGET'].notnull()].copy()  # .copy() pour éviter les SettingWithCopyWarning\n",
    "    test_df = df[df['TARGET'].isnull()].copy()\n",
    "    print(\"Starting LightGBM. Train shape: {}, test shape: {}\".format(train_df.shape, test_df.shape))\n",
    "    \n",
    "    # Conversion de type forcée (ajoutée pendant le débogage)\n",
    "    # S'assure que les colonnes sont numériques avant l'entraînement\n",
    "    print(\"\\nForçage de la conversion des types 'object' en numérique dans train_df et test_df:\")\n",
    "    feats_to_process = [f for f in train_df.columns if f not in ['TARGET','SK_ID_CURR','SK_ID_BUREAU','SK_ID_PREV','index']]\n",
    "    for current_df in [train_df, test_df]:\n",
    "        for col in feats_to_process:\n",
    "            if col in current_df.columns:\n",
    "                if current_df[col].dtype == 'object':\n",
    "                    print(f\"Dans {('train_df' if current_df is train_df else 'test_df')}, conversion de la colonne '{col}' en numérique.\")\n",
    "                    current_df[col] = pd.to_numeric(current_df[col], errors='coerce')\n",
    "    print(\"Fin du forçage de la conversion des types.\")\n",
    "\n",
    "    # Configuration de la validation croisée\n",
    "    if stratified:\n",
    "        folds = StratifiedKFold(n_splits=num_folds, shuffle=True, random_state=1001)\n",
    "    else:\n",
    "        folds = KFold(n_splits=num_folds, shuffle=True, random_state=1001)\n",
    "        \n",
    "    # Initialisation des tableaux pour stocker les prédictions et l'importance des caractéristiques\n",
    "    oof_preds = np.zeros(train_df.shape[0])  # Prédictions Out-Of-Fold pour l'ensemble d'entraînement\n",
    "    sub_preds = np.zeros(test_df.shape[0])   # Prédictions pour l'ensemble de test (sera moyenné sur les plis)\n",
    "    feature_importance_df = pd.DataFrame()   # Pour stocker l'importance des caractéristiques de chaque pli\n",
    "    \n",
    "    # Sélection des caractéristiques à utiliser pour l'entraînement\n",
    "    # Exclut la cible, les identifiants et un éventuel index hérité\n",
    "    feats = [f for f in train_df.columns if f not in ['TARGET','SK_ID_CURR','SK_ID_BUREAU','SK_ID_PREV','index']]\n",
    "    \n",
    "    # Boucle de validation croisée\n",
    "    for n_fold, (train_idx, valid_idx) in enumerate(folds.split(train_df[feats], train_df['TARGET'])):\n",
    "        # Séparation des données pour le pli courant\n",
    "        train_x, train_y = train_df[feats].iloc[train_idx], train_df['TARGET'].iloc[train_idx]\n",
    "        valid_x, valid_y = train_df[feats].iloc[valid_idx], train_df['TARGET'].iloc[valid_idx]\n",
    "\n",
    "        # Vérification des types dans train_x juste avant l'appel à clf.fit() (ajoutée pendant le débogage)\n",
    "        print(\"\\nVérification des types dans train_x juste avant l'appel à clf.fit():\")\n",
    "        object_cols_in_train_x = train_x.select_dtypes(include=['object']).columns\n",
    "        if len(object_cols_in_train_x) > 0:\n",
    "            print(\"Colonnes de type 'object' trouvées dans train_x :\")\n",
    "            for col_check in object_cols_in_train_x:\n",
    "                print(f\"- {col_check}: {train_x[col_check].dtype}\")\n",
    "        else:\n",
    "            print(\"Aucune colonne de type 'object' trouvée dans train_x. Tous les types semblent corrects.\")\n",
    "        \n",
    "        # Initialisation du classifieur LightGBM\n",
    "        # Paramètres issus d'une optimisation bayésienne (selon le commentaire original du kernel)\n",
    "        clf = lgb.LGBMClassifier(\n",
    "            nthread=4,  # Nombre de threads (peut être mis à -1 pour utiliser tous les cœurs)\n",
    "            n_estimators=10000,  # Nombre maximal d'arbres (l'arrêt anticipé en déterminera le nombre optimal)\n",
    "            learning_rate=0.02, # Taux d'apprentissage\n",
    "            num_leaves=34,       # Nombre maximal de feuilles par arbre\n",
    "            colsample_bytree=0.9497036, # Pourcentage de caractéristiques utilisées par arbre\n",
    "            subsample=0.8715623,      # Pourcentage d'échantillons utilisés par arbre\n",
    "            max_depth=8,             # Profondeur maximale de l'arbre\n",
    "            reg_alpha=0.041545473,   # Régularisation L1\n",
    "            reg_lambda=0.0735294,  # Régularisation L2\n",
    "            min_split_gain=0.0222415, # Gain minimal pour effectuer une division\n",
    "            min_child_weight=39.3259775, # Poids minimal des enfants requis pour une division\n",
    "            verbose=-1, # Contrôle la verbosité du moteur LightGBM (-1 = erreurs/warnings seulement)\n",
    "                        # Le paramètre 'silent' est déprécié en faveur de 'verbose'.\n",
    "        )\n",
    "\n",
    "        # Définition des callbacks pour l'entraînement\n",
    "        callbacks = []\n",
    "        # Arrêt anticipé: arrête l'entraînement si le score sur l'ensemble de validation ne s'améliore pas pendant 'stopping_rounds'\n",
    "        callbacks.append(lgb.early_stopping(stopping_rounds=200, verbose=True)) \n",
    "        # Log des évaluations: affiche les métriques d'évaluation toutes les 'period' itérations\n",
    "        callbacks.append(lgb.log_evaluation(period=200))\n",
    "        \n",
    "        # Entraînement du modèle\n",
    "        clf.fit(train_x, train_y, eval_set=[(train_x, train_y), (valid_x, valid_y)],\n",
    "                eval_metric='auc',  # Métrique d'évaluation utilisée pour l'arrêt anticipé\n",
    "                callbacks=callbacks)\n",
    "\n",
    "        # Prédictions sur l'ensemble de validation (pour OOF) et sur l'ensemble de test\n",
    "        # predict_proba retourne les probabilités pour chaque classe, [:, 1] sélectionne la probabilité de la classe positive (défaut)\n",
    "        # num_iteration=clf.best_iteration_ utilise le nombre optimal d'arbres trouvé par l'arrêt anticipé\n",
    "        oof_preds[valid_idx] = clf.predict_proba(valid_x, num_iteration=clf.best_iteration_)[:, 1]\n",
    "        sub_preds += clf.predict_proba(test_df[feats], num_iteration=clf.best_iteration_)[:, 1] / folds.n_splits # Moyenne des prédictions sur les plis\n",
    "\n",
    "        # Stockage de l'importance des caractéristiques pour ce pli\n",
    "        fold_importance_df = pd.DataFrame()\n",
    "        fold_importance_df[\"feature\"] = feats\n",
    "        fold_importance_df[\"importance\"] = clf.feature_importances_\n",
    "        fold_importance_df[\"fold\"] = n_fold + 1\n",
    "        feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n",
    "        \n",
    "        print('Fold %2d AUC : %.6f' % (n_fold + 1, roc_auc_score(valid_y, oof_preds[valid_idx])))\n",
    "        del clf, train_x, train_y, valid_x, valid_y # Libération de mémoire\n",
    "        gc.collect()\n",
    "\n",
    "    # Affichage du score AUC global sur les prédictions OOF\n",
    "    print('Full AUC score %.6f' % roc_auc_score(train_df['TARGET'], oof_preds))\n",
    "    \n",
    "    # Création du fichier de soumission et affichage de l'importance des caractéristiques (si pas en mode debug)\n",
    "    if not debug:\n",
    "        test_df['TARGET'] = sub_preds # Assigne les prédictions moyennées à la colonne TARGET du jeu de test\n",
    "        test_df[['SK_ID_CURR', 'TARGET']].to_csv(submission_file_name, index=False) # Sauvegarde\n",
    "        \n",
    "    display_importances(feature_importance_df) # Affiche et sauvegarde le graphique des importances\n",
    "    return feature_importance_df\n",
    "\n",
    "# --- Fonction d'Affichage de l'Importance des Caractéristiques ---\n",
    "\n",
    "def display_importances(feature_importance_df_):\n",
    "    \"\"\"\n",
    "    Affiche et sauvegarde un graphique de l'importance des caractéristiques.\n",
    "\n",
    "    Args:\n",
    "        feature_importance_df_ (pd.DataFrame): DataFrame contenant les caractéristiques, \n",
    "                                               leur importance, et le numéro du pli.\n",
    "    \"\"\"\n",
    "    # Calcule l'importance moyenne pour chaque caractéristique sur tous les plis\n",
    "    # et sélectionne les 40 plus importantes\n",
    "    cols = feature_importance_df_[[\"feature\", \"importance\"]].groupby(\"feature\").mean().sort_values(by=\"importance\", ascending=False)[:40].index\n",
    "    best_features = feature_importance_df_.loc[feature_importance_df_.feature.isin(cols)]\n",
    "    \n",
    "    plt.figure(figsize=(8, 10)) # Définit la taille du graphique\n",
    "    # Crée un barplot avec seaborn\n",
    "    sns.barplot(x=\"importance\", y=\"feature\", data=best_features.sort_values(by=\"importance\", ascending=False))\n",
    "    plt.title('LightGBM Features (avg over folds)') # Titre du graphique\n",
    "    plt.tight_layout() # Ajuste automatiquement les paramètres du graphique pour un bon affichage\n",
    "    plt.savefig('lgbm_importances01.png') # Sauvegarde le graphique\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d48c5613-09e9-4d8d-b7a0-14bd2a9961ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train samples: 307511, test samples: 48744\n",
      "Bureau df shape: (305811, 116)\n",
      "Process bureau and bureau_balance - done in 13s\n",
      "Previous applications df shape: (338857, 249)\n",
      "Process previous_applications - done in 13s\n",
      "Pos-cash balance df shape: (337252, 18)\n",
      "Process POS-CASH balance - done in 7s\n",
      "Installments payments df shape: (339587, 26)\n",
      "Process installments payments - done in 16s\n",
      "Credit card balance df shape: (103558, 141)\n",
      "Process credit card balance - done in 10s\n",
      "\n",
      "Nettoyage des noms de colonnes pour LightGBM...\n",
      "Noms de colonnes nettoyés.\n",
      "\n",
      "DATASET TRAIN PRET POUR MODELISATION :\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SK_ID_CURR</th>\n",
       "      <th>TARGET</th>\n",
       "      <th>CODE_GENDER</th>\n",
       "      <th>FLAG_OWN_CAR</th>\n",
       "      <th>FLAG_OWN_REALTY</th>\n",
       "      <th>CNT_CHILDREN</th>\n",
       "      <th>AMT_INCOME_TOTAL</th>\n",
       "      <th>AMT_CREDIT</th>\n",
       "      <th>AMT_ANNUITY</th>\n",
       "      <th>AMT_GOODS_PRICE</th>\n",
       "      <th>...</th>\n",
       "      <th>CC_NAME_CONTRACT_STATUS_Signed_MAX</th>\n",
       "      <th>CC_NAME_CONTRACT_STATUS_Signed_MEAN</th>\n",
       "      <th>CC_NAME_CONTRACT_STATUS_Signed_SUM</th>\n",
       "      <th>CC_NAME_CONTRACT_STATUS_Signed_VAR</th>\n",
       "      <th>CC_NAME_CONTRACT_STATUS_nan_MIN</th>\n",
       "      <th>CC_NAME_CONTRACT_STATUS_nan_MAX</th>\n",
       "      <th>CC_NAME_CONTRACT_STATUS_nan_MEAN</th>\n",
       "      <th>CC_NAME_CONTRACT_STATUS_nan_SUM</th>\n",
       "      <th>CC_NAME_CONTRACT_STATUS_nan_VAR</th>\n",
       "      <th>CC_COUNT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100002</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>202500.0</td>\n",
       "      <td>406597.5</td>\n",
       "      <td>24700.5</td>\n",
       "      <td>351000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100003</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>270000.0</td>\n",
       "      <td>1293502.5</td>\n",
       "      <td>35698.5</td>\n",
       "      <td>1129500.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100004</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>67500.0</td>\n",
       "      <td>135000.0</td>\n",
       "      <td>6750.0</td>\n",
       "      <td>135000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100006</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>135000.0</td>\n",
       "      <td>312682.5</td>\n",
       "      <td>29686.5</td>\n",
       "      <td>297000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100007</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>121500.0</td>\n",
       "      <td>513000.0</td>\n",
       "      <td>21865.5</td>\n",
       "      <td>513000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>100008</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>99000.0</td>\n",
       "      <td>490495.5</td>\n",
       "      <td>27517.5</td>\n",
       "      <td>454500.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>100009</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>171000.0</td>\n",
       "      <td>1560726.0</td>\n",
       "      <td>41301.0</td>\n",
       "      <td>1395000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>100010</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>360000.0</td>\n",
       "      <td>1530000.0</td>\n",
       "      <td>42075.0</td>\n",
       "      <td>1530000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>100011</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>112500.0</td>\n",
       "      <td>1019610.0</td>\n",
       "      <td>33826.5</td>\n",
       "      <td>913500.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>74.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>100012</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>135000.0</td>\n",
       "      <td>405000.0</td>\n",
       "      <td>20250.0</td>\n",
       "      <td>405000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 797 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   SK_ID_CURR  TARGET  CODE_GENDER  FLAG_OWN_CAR  FLAG_OWN_REALTY  \\\n",
       "0      100002     1.0            0             0                0   \n",
       "1      100003     0.0            1             0                1   \n",
       "2      100004     0.0            0             1                0   \n",
       "3      100006     0.0            1             0                0   \n",
       "4      100007     0.0            0             0                0   \n",
       "5      100008     0.0            0             0                0   \n",
       "6      100009     0.0            1             1                0   \n",
       "7      100010     0.0            0             1                0   \n",
       "8      100011     0.0            1             0                0   \n",
       "9      100012     0.0            0             0                0   \n",
       "\n",
       "   CNT_CHILDREN  AMT_INCOME_TOTAL  AMT_CREDIT  AMT_ANNUITY  AMT_GOODS_PRICE  \\\n",
       "0             0          202500.0    406597.5      24700.5         351000.0   \n",
       "1             0          270000.0   1293502.5      35698.5        1129500.0   \n",
       "2             0           67500.0    135000.0       6750.0         135000.0   \n",
       "3             0          135000.0    312682.5      29686.5         297000.0   \n",
       "4             0          121500.0    513000.0      21865.5         513000.0   \n",
       "5             0           99000.0    490495.5      27517.5         454500.0   \n",
       "6             1          171000.0   1560726.0      41301.0        1395000.0   \n",
       "7             0          360000.0   1530000.0      42075.0        1530000.0   \n",
       "8             0          112500.0   1019610.0      33826.5         913500.0   \n",
       "9             0          135000.0    405000.0      20250.0         405000.0   \n",
       "\n",
       "   ...  CC_NAME_CONTRACT_STATUS_Signed_MAX  \\\n",
       "0  ...                                 NaN   \n",
       "1  ...                                 NaN   \n",
       "2  ...                                 NaN   \n",
       "3  ...                               False   \n",
       "4  ...                                 NaN   \n",
       "5  ...                                 NaN   \n",
       "6  ...                                 NaN   \n",
       "7  ...                                 NaN   \n",
       "8  ...                               False   \n",
       "9  ...                                 NaN   \n",
       "\n",
       "   CC_NAME_CONTRACT_STATUS_Signed_MEAN  CC_NAME_CONTRACT_STATUS_Signed_SUM  \\\n",
       "0                                  NaN                                 NaN   \n",
       "1                                  NaN                                 NaN   \n",
       "2                                  NaN                                 NaN   \n",
       "3                                  0.0                                 0.0   \n",
       "4                                  NaN                                 NaN   \n",
       "5                                  NaN                                 NaN   \n",
       "6                                  NaN                                 NaN   \n",
       "7                                  NaN                                 NaN   \n",
       "8                                  0.0                                 0.0   \n",
       "9                                  NaN                                 NaN   \n",
       "\n",
       "   CC_NAME_CONTRACT_STATUS_Signed_VAR  CC_NAME_CONTRACT_STATUS_nan_MIN  \\\n",
       "0                                 NaN                              NaN   \n",
       "1                                 NaN                              NaN   \n",
       "2                                 NaN                              NaN   \n",
       "3                                 0.0                            False   \n",
       "4                                 NaN                              NaN   \n",
       "5                                 NaN                              NaN   \n",
       "6                                 NaN                              NaN   \n",
       "7                                 NaN                              NaN   \n",
       "8                                 0.0                            False   \n",
       "9                                 NaN                              NaN   \n",
       "\n",
       "   CC_NAME_CONTRACT_STATUS_nan_MAX  CC_NAME_CONTRACT_STATUS_nan_MEAN  \\\n",
       "0                              NaN                               NaN   \n",
       "1                              NaN                               NaN   \n",
       "2                              NaN                               NaN   \n",
       "3                            False                               0.0   \n",
       "4                              NaN                               NaN   \n",
       "5                              NaN                               NaN   \n",
       "6                              NaN                               NaN   \n",
       "7                              NaN                               NaN   \n",
       "8                            False                               0.0   \n",
       "9                              NaN                               NaN   \n",
       "\n",
       "   CC_NAME_CONTRACT_STATUS_nan_SUM  CC_NAME_CONTRACT_STATUS_nan_VAR  CC_COUNT  \n",
       "0                              NaN                              NaN       NaN  \n",
       "1                              NaN                              NaN       NaN  \n",
       "2                              NaN                              NaN       NaN  \n",
       "3                              0.0                              0.0       6.0  \n",
       "4                              NaN                              NaN       NaN  \n",
       "5                              NaN                              NaN       NaN  \n",
       "6                              NaN                              NaN       NaN  \n",
       "7                              NaN                              NaN       NaN  \n",
       "8                              0.0                              0.0      74.0  \n",
       "9                              NaN                              NaN       NaN  \n",
       "\n",
       "[10 rows x 797 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DATASET TEST PRET POUR MODELISATION :\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SK_ID_CURR</th>\n",
       "      <th>TARGET</th>\n",
       "      <th>CODE_GENDER</th>\n",
       "      <th>FLAG_OWN_CAR</th>\n",
       "      <th>FLAG_OWN_REALTY</th>\n",
       "      <th>CNT_CHILDREN</th>\n",
       "      <th>AMT_INCOME_TOTAL</th>\n",
       "      <th>AMT_CREDIT</th>\n",
       "      <th>AMT_ANNUITY</th>\n",
       "      <th>AMT_GOODS_PRICE</th>\n",
       "      <th>...</th>\n",
       "      <th>CC_NAME_CONTRACT_STATUS_Signed_MAX</th>\n",
       "      <th>CC_NAME_CONTRACT_STATUS_Signed_MEAN</th>\n",
       "      <th>CC_NAME_CONTRACT_STATUS_Signed_SUM</th>\n",
       "      <th>CC_NAME_CONTRACT_STATUS_Signed_VAR</th>\n",
       "      <th>CC_NAME_CONTRACT_STATUS_nan_MIN</th>\n",
       "      <th>CC_NAME_CONTRACT_STATUS_nan_MAX</th>\n",
       "      <th>CC_NAME_CONTRACT_STATUS_nan_MEAN</th>\n",
       "      <th>CC_NAME_CONTRACT_STATUS_nan_SUM</th>\n",
       "      <th>CC_NAME_CONTRACT_STATUS_nan_VAR</th>\n",
       "      <th>CC_COUNT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>307511</th>\n",
       "      <td>100001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>135000.0</td>\n",
       "      <td>568800.0</td>\n",
       "      <td>20560.5</td>\n",
       "      <td>450000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307512</th>\n",
       "      <td>100005</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>99000.0</td>\n",
       "      <td>222768.0</td>\n",
       "      <td>17370.0</td>\n",
       "      <td>180000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307513</th>\n",
       "      <td>100013</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>202500.0</td>\n",
       "      <td>663264.0</td>\n",
       "      <td>69777.0</td>\n",
       "      <td>630000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>96.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307514</th>\n",
       "      <td>100028</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>315000.0</td>\n",
       "      <td>1575000.0</td>\n",
       "      <td>49018.5</td>\n",
       "      <td>1575000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>49.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307515</th>\n",
       "      <td>100038</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>180000.0</td>\n",
       "      <td>625500.0</td>\n",
       "      <td>32067.0</td>\n",
       "      <td>625500.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307516</th>\n",
       "      <td>100042</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>270000.0</td>\n",
       "      <td>959688.0</td>\n",
       "      <td>34600.5</td>\n",
       "      <td>810000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>84.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307517</th>\n",
       "      <td>100057</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>180000.0</td>\n",
       "      <td>499221.0</td>\n",
       "      <td>22117.5</td>\n",
       "      <td>373500.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307518</th>\n",
       "      <td>100065</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>166500.0</td>\n",
       "      <td>180000.0</td>\n",
       "      <td>14220.0</td>\n",
       "      <td>180000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307519</th>\n",
       "      <td>100066</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>315000.0</td>\n",
       "      <td>364896.0</td>\n",
       "      <td>28957.5</td>\n",
       "      <td>315000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307520</th>\n",
       "      <td>100067</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>162000.0</td>\n",
       "      <td>45000.0</td>\n",
       "      <td>5337.0</td>\n",
       "      <td>45000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>87.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 797 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        SK_ID_CURR  TARGET  CODE_GENDER  FLAG_OWN_CAR  FLAG_OWN_REALTY  \\\n",
       "307511      100001     NaN            1             0                0   \n",
       "307512      100005     NaN            0             0                0   \n",
       "307513      100013     NaN            0             1                0   \n",
       "307514      100028     NaN            1             0                0   \n",
       "307515      100038     NaN            0             1                1   \n",
       "307516      100042     NaN            1             1                0   \n",
       "307517      100057     NaN            0             1                0   \n",
       "307518      100065     NaN            0             0                0   \n",
       "307519      100066     NaN            1             0                0   \n",
       "307520      100067     NaN            1             1                0   \n",
       "\n",
       "        CNT_CHILDREN  AMT_INCOME_TOTAL  AMT_CREDIT  AMT_ANNUITY  \\\n",
       "307511             0          135000.0    568800.0      20560.5   \n",
       "307512             0           99000.0    222768.0      17370.0   \n",
       "307513             0          202500.0    663264.0      69777.0   \n",
       "307514             2          315000.0   1575000.0      49018.5   \n",
       "307515             1          180000.0    625500.0      32067.0   \n",
       "307516             0          270000.0    959688.0      34600.5   \n",
       "307517             2          180000.0    499221.0      22117.5   \n",
       "307518             0          166500.0    180000.0      14220.0   \n",
       "307519             0          315000.0    364896.0      28957.5   \n",
       "307520             1          162000.0     45000.0       5337.0   \n",
       "\n",
       "        AMT_GOODS_PRICE  ...  CC_NAME_CONTRACT_STATUS_Signed_MAX  \\\n",
       "307511         450000.0  ...                                 NaN   \n",
       "307512         180000.0  ...                                 NaN   \n",
       "307513         630000.0  ...                               False   \n",
       "307514        1575000.0  ...                               False   \n",
       "307515         625500.0  ...                                 NaN   \n",
       "307516         810000.0  ...                               False   \n",
       "307517         373500.0  ...                                 NaN   \n",
       "307518         180000.0  ...                                 NaN   \n",
       "307519         315000.0  ...                               False   \n",
       "307520          45000.0  ...                               False   \n",
       "\n",
       "        CC_NAME_CONTRACT_STATUS_Signed_MEAN  \\\n",
       "307511                                  NaN   \n",
       "307512                                  NaN   \n",
       "307513                                  0.0   \n",
       "307514                                  0.0   \n",
       "307515                                  NaN   \n",
       "307516                                  0.0   \n",
       "307517                                  NaN   \n",
       "307518                                  NaN   \n",
       "307519                                  0.0   \n",
       "307520                                  0.0   \n",
       "\n",
       "        CC_NAME_CONTRACT_STATUS_Signed_SUM  \\\n",
       "307511                                 NaN   \n",
       "307512                                 NaN   \n",
       "307513                                 0.0   \n",
       "307514                                 0.0   \n",
       "307515                                 NaN   \n",
       "307516                                 0.0   \n",
       "307517                                 NaN   \n",
       "307518                                 NaN   \n",
       "307519                                 0.0   \n",
       "307520                                 0.0   \n",
       "\n",
       "        CC_NAME_CONTRACT_STATUS_Signed_VAR  CC_NAME_CONTRACT_STATUS_nan_MIN  \\\n",
       "307511                                 NaN                              NaN   \n",
       "307512                                 NaN                              NaN   \n",
       "307513                                 0.0                            False   \n",
       "307514                                 0.0                            False   \n",
       "307515                                 NaN                              NaN   \n",
       "307516                                 0.0                            False   \n",
       "307517                                 NaN                              NaN   \n",
       "307518                                 NaN                              NaN   \n",
       "307519                                 0.0                            False   \n",
       "307520                                 0.0                            False   \n",
       "\n",
       "        CC_NAME_CONTRACT_STATUS_nan_MAX  CC_NAME_CONTRACT_STATUS_nan_MEAN  \\\n",
       "307511                              NaN                               NaN   \n",
       "307512                              NaN                               NaN   \n",
       "307513                            False                               0.0   \n",
       "307514                            False                               0.0   \n",
       "307515                              NaN                               NaN   \n",
       "307516                            False                               0.0   \n",
       "307517                              NaN                               NaN   \n",
       "307518                              NaN                               NaN   \n",
       "307519                            False                               0.0   \n",
       "307520                            False                               0.0   \n",
       "\n",
       "        CC_NAME_CONTRACT_STATUS_nan_SUM  CC_NAME_CONTRACT_STATUS_nan_VAR  \\\n",
       "307511                              NaN                              NaN   \n",
       "307512                              NaN                              NaN   \n",
       "307513                              0.0                              0.0   \n",
       "307514                              0.0                              0.0   \n",
       "307515                              NaN                              NaN   \n",
       "307516                              0.0                              0.0   \n",
       "307517                              NaN                              NaN   \n",
       "307518                              NaN                              NaN   \n",
       "307519                              0.0                              0.0   \n",
       "307520                              0.0                              0.0   \n",
       "\n",
       "        CC_COUNT  \n",
       "307511       NaN  \n",
       "307512       NaN  \n",
       "307513      96.0  \n",
       "307514      49.0  \n",
       "307515       NaN  \n",
       "307516      84.0  \n",
       "307517       NaN  \n",
       "307518       NaN  \n",
       "307519      15.0  \n",
       "307520      87.0  \n",
       "\n",
       "[10 rows x 797 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Export en CSV des dataframes train et test...\n",
      "Export terminé.\n",
      "Full model run - done in 163s\n"
     ]
    }
   ],
   "source": [
    "# --- Fonction Principale d'Orchestration ---\n",
    "\n",
    "def main(debug=False):\n",
    "    \"\"\"\n",
    "    Fonction principale qui orchestre le chargement des données, le prétraitement,\n",
    "    l'ingénierie de caractéristiques, le nettoyage des noms de colonnes et l'entraînement du modèle.\n",
    "\n",
    "    Args:\n",
    "        debug (bool, optional): Si True, charge un nombre réduit de lignes pour accélérer l'exécution.\n",
    "                                Par défaut à False.\n",
    "    \"\"\"\n",
    "    num_rows = 10000 if debug else None # Définit le nombre de lignes à charger en mode debug\n",
    "    \n",
    "    # Étape 1: Prétraitement des données d'application (train + test)\n",
    "    df = application_train_test(num_rows)\n",
    "    \n",
    "    # Étapes suivantes: Prétraitement des autres tables et jointure avec df principal\n",
    "    with timer(\"Process bureau and bureau_balance\"):\n",
    "        bureau = bureau_and_balance(num_rows)\n",
    "        print(\"Bureau df shape:\", bureau.shape)\n",
    "        df = df.join(bureau, how='left', on='SK_ID_CURR') # Jointure sur SK_ID_CURR\n",
    "        del bureau\n",
    "        gc.collect()\n",
    "        \n",
    "    with timer(\"Process previous_applications\"):\n",
    "        prev = previous_applications(num_rows)\n",
    "        print(\"Previous applications df shape:\", prev.shape)\n",
    "        df = df.join(prev, how='left', on='SK_ID_CURR')\n",
    "        del prev\n",
    "        gc.collect()\n",
    "        \n",
    "    with timer(\"Process POS-CASH balance\"):\n",
    "        pos = pos_cash(num_rows)\n",
    "        print(\"Pos-cash balance df shape:\", pos.shape)\n",
    "        df = df.join(pos, how='left', on='SK_ID_CURR')\n",
    "        del pos\n",
    "        gc.collect()\n",
    "        \n",
    "    with timer(\"Process installments payments\"):\n",
    "        ins = installments_payments(num_rows)\n",
    "        print(\"Installments payments df shape:\", ins.shape)\n",
    "        df = df.join(ins, how='left', on='SK_ID_CURR')\n",
    "        del ins\n",
    "        gc.collect()\n",
    "        \n",
    "    with timer(\"Process credit card balance\"):\n",
    "        cc = credit_card_balance(num_rows)\n",
    "        print(\"Credit card balance df shape:\", cc.shape)\n",
    "        df = df.join(cc, how='left', on='SK_ID_CURR')\n",
    "        del cc\n",
    "        gc.collect()\n",
    "\n",
    "    # Nettoyage des noms de colonnes pour compatibilité avec LightGBM (ajouté pendant le débogage)\n",
    "    print(\"\\nNettoyage des noms de colonnes pour LightGBM...\")\n",
    "    original_columns = list(df.columns)\n",
    "    sanitized_columns_map = {col: sanitize_lgbm_col_name(col) for col in original_columns}\n",
    "    df.rename(columns=sanitized_columns_map, inplace=True)\n",
    "    \n",
    "    # Gestion des noms de colonnes dupliqués potentiels après nettoyage\n",
    "    if len(df.columns) != len(set(df.columns)):\n",
    "        print(\"Attention : Des noms de colonnes dupliqués ont été créés après le nettoyage !\")\n",
    "        seen = {}\n",
    "        new_cols = []\n",
    "        for col_idx, col_name in enumerate(df.columns): # Utiliser enumerate pour accéder à l'index si besoin, ici juste le nom\n",
    "            if col_name not in seen:\n",
    "                seen[col_name] = 1\n",
    "                new_cols.append(col_name)\n",
    "            else:\n",
    "                # Si le nom de colonne est déjà vu, on ajoute un suffixe pour le rendre unique\n",
    "                # Par exemple, si 'col' apparaît 3 fois, on aura 'col', 'col_1', 'col_2'\n",
    "                # (correction: le suffixe doit commencer à partir de la 2ème occurrence)\n",
    "                suffix_num = seen[col_name]\n",
    "                new_cols.append(f\"{col_name}_{suffix_num}\") \n",
    "                seen[col_name] += 1\n",
    "        df.columns = new_cols # Assigne la nouvelle liste de noms de colonnes (uniques)\n",
    "        print(\"Noms de colonnes dupliqués renommés.\")\n",
    "\n",
    "    print(\"Noms de colonnes nettoyés.\")\n",
    "    \n",
    "    # Exécution de l'entraînement et de la prédiction avec LightGBM\n",
    "    # PARTIE MODELISATION COMMENTEE POUR NE CONSERVER QUE LE FEATURE ENGINEERING\n",
    "    # with timer(\"Run LightGBM with kfold\"):\n",
    "    #     feat_importance = kfold_lightgbm(df, num_folds=10, stratified=False, debug=debug)\n",
    "\n",
    "    # Séparation des dataframes train et test\n",
    "    train_df = df[df['TARGET'].notnull()].copy()  # .copy() pour éviter les SettingWithCopyWarning\n",
    "    test_df = df[df['TARGET'].isnull()].copy()\n",
    "\n",
    "    # Affichage des premières lignes des dataframes train et test\n",
    "    print(f\"\\nDATASET TRAIN PRET POUR MODELISATION :\\n\")\n",
    "    display(train_df.head(10))\n",
    "    print(f\"\\nDATASET TEST PRET POUR MODELISATION :\\n\")\n",
    "    display(test_df.head(10))\n",
    "\n",
    "    print(f\"Export en CSV des dataframes train et test...\")\n",
    "    train_df.to_csv(\"./data/application_train_rdy.csv\")\n",
    "    test_df.to_csv(\"./data/application_test_rdy.csv\")\n",
    "    print(f\"Export terminé.\")\n",
    "\n",
    "# --- Point d'entrée du script ---\n",
    "if __name__ == \"__main__\":\n",
    "    # Ce bloc s'exécute uniquement si le script est lancé directement \n",
    "    # (et non importé comme module dans un autre script)\n",
    "    submission_file_name = \"submission_kernel02.csv\" # Nom du fichier de soumission\n",
    "    with timer(\"Full model run\"): # Chronomètre l'exécution complète de la fonction main\n",
    "        main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
